{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from Tool import mesh_data_label\n",
    "device ='cpu'\n",
    "mesh_file = 'ADP/ADP.mesh'\n",
    "pqr_file = 'ADP/transfer_ADP.pqr'\n",
    "\n",
    "model=torch.load('49999model.pkl',map_location='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2data(csv_file, em, es):\n",
    "    inner_point,inner_label,G ,out_point,out_label, boundary_point, boundary_label = mesh_data_label(mesh_file,csv_file,device)\n",
    "    test_inner = torch.hstack((torch.tile(em, (inner_point.shape[0], 1)), torch.tile(es, (inner_point.shape[0], 1)), inner_point, inner_label, G))\n",
    "    test_inner = (test_inner[...,0:1],test_inner[...,1:2],test_inner[...,2:5],test_inner[...,5:6],test_inner[...,6:])\n",
    "    test_out1 = torch.hstack((torch.tile(em, (out_point.shape[0], 1)), torch.tile(es, (out_point.shape[0], 1)), out_point, out_label))\n",
    "    test_out2=  torch.hstack((torch.tile(em, (boundary_point.shape[0], 1)), torch.tile(es, (boundary_point.shape[0], 1)), boundary_point, boundary_label))\n",
    "    test_out =torch.vstack((test_out1,test_out2))\n",
    "    test_out = (test_out[...,0:1],test_out[...,1:2],test_out[...,2:5],test_out[...,5:])\n",
    "\n",
    "    return test_inner, test_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-259.5420, grad_fn=<MulBackward0>)\n",
      "tensor(-374.5126, grad_fn=<MulBackward0>)\n",
      "tensor(-527.1140, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from Tool import read_pqr\n",
    "centers,_, qs = read_pqr(pqr_file,device)\n",
    "test_epsilon_m, test_epsilon_s = torch.tensor([[2.]]), torch.tensor([[80.]])\n",
    "num=centers.shape[0]\n",
    "x_enegy = torch.hstack((torch.tile(test_epsilon_m[0], (num, 1)), torch.tile(test_epsilon_s[0], (num, 1)), centers))\n",
    "x_enegy =(x_enegy[...,0:1],x_enegy[...,1:2],x_enegy[...,2:])\n",
    "print(0.5927830*0.5*torch.sum(qs.view(-1,1)*model(x_enegy,label='inner')))\n",
    "\n",
    "\n",
    "test_epsilon_m, test_epsilon_s = torch.tensor([[1.4]]), torch.tensor([[88.]])\n",
    "num=centers.shape[0]\n",
    "x_enegy = torch.hstack((torch.tile(test_epsilon_m[0], (num, 1)), torch.tile(test_epsilon_s[0], (num, 1)), centers))\n",
    "x_enegy =(x_enegy[...,0:1],x_enegy[...,1:2],x_enegy[...,2:])\n",
    "print(0.5927830*0.5*torch.sum(qs.view(-1,1)*model(x_enegy,label='inner')))\n",
    "\n",
    "\n",
    "test_epsilon_m, test_epsilon_s = torch.tensor([[1]]), torch.tensor([[100.]])\n",
    "num=centers.shape[0]\n",
    "x_enegy = torch.hstack((torch.tile(test_epsilon_m[0], (num, 1)), torch.tile(test_epsilon_s[0], (num, 1)), centers))\n",
    "x_enegy =(x_enegy[...,0:1],x_enegy[...,1:2],x_enegy[...,2:])\n",
    "print(0.5927830*0.5*torch.sum(qs.view(-1,1)*model(x_enegy,label='inner')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data/ADP_10_80.csv tensor(1.) tensor(80) 0.016721880063414574\n",
      "test data/ADP_10_84.csv tensor(1.) tensor(84) 0.016580065712332726\n",
      "test data/ADP_10_88.csv tensor(1.) tensor(88) 0.0165322907269001\n",
      "test data/ADP_10_92.csv tensor(1.) tensor(92) 0.01650310307741165\n",
      "test data/ADP_10_96.csv tensor(1.) tensor(96) 0.016421904787421227\n",
      "test data/ADP_10_100.csv tensor(1.) tensor(100) 0.01624622382223606\n",
      "test data/ADP_12_80.csv tensor(1.2000) tensor(80) 0.017130590975284576\n",
      "test data/ADP_12_84.csv tensor(1.2000) tensor(84) 0.017010096460580826\n",
      "test data/ADP_12_88.csv tensor(1.2000) tensor(88) 0.01701657474040985\n",
      "test data/ADP_12_92.csv tensor(1.2000) tensor(92) 0.017056604847311974\n",
      "test data/ADP_12_96.csv tensor(1.2000) tensor(96) 0.017032872885465622\n",
      "test data/ADP_12_100.csv tensor(1.2000) tensor(100) 0.016872607171535492\n",
      "test data/ADP_14_80.csv tensor(1.4000) tensor(80) 0.017123213037848473\n",
      "test data/ADP_14_84.csv tensor(1.4000) tensor(84) 0.017034072428941727\n",
      "test data/ADP_14_88.csv tensor(1.4000) tensor(88) 0.017059462144970894\n",
      "test data/ADP_14_92.csv tensor(1.4000) tensor(92) 0.017111236229538918\n",
      "test data/ADP_14_96.csv tensor(1.4000) tensor(96) 0.01709592714905739\n",
      "test data/ADP_14_100.csv tensor(1.4000) tensor(100) 0.016941748559474945\n",
      "test data/ADP_16_80.csv tensor(1.6000) tensor(80) 0.017146747559309006\n",
      "test data/ADP_16_84.csv tensor(1.6000) tensor(84) 0.017034703865647316\n",
      "test data/ADP_16_88.csv tensor(1.6000) tensor(88) 0.017028208822011948\n",
      "test data/ADP_16_92.csv tensor(1.6000) tensor(92) 0.01704670488834381\n",
      "test data/ADP_16_96.csv tensor(1.6000) tensor(96) 0.01700473204255104\n",
      "test data/ADP_16_100.csv tensor(1.6000) tensor(100) 0.016835588961839676\n",
      "test data/ADP_18_80.csv tensor(1.8000) tensor(80) 0.017210202291607857\n",
      "test data/ADP_18_84.csv tensor(1.8000) tensor(84) 0.017047306522727013\n",
      "test data/ADP_18_88.csv tensor(1.8000) tensor(88) 0.0169936902821064\n",
      "test data/ADP_18_92.csv tensor(1.8000) tensor(92) 0.01697106845676899\n",
      "test data/ADP_18_96.csv tensor(1.8000) tensor(96) 0.01689898781478405\n",
      "test data/ADP_18_100.csv tensor(1.8000) tensor(100) 0.016714414581656456\n",
      "test data/ADP_20_80.csv tensor(2.) tensor(80) 0.01733866147696972\n",
      "test data/ADP_20_84.csv tensor(2.) tensor(84) 0.017141062766313553\n",
      "test data/ADP_20_88.csv tensor(2.) tensor(88) 0.017070606350898743\n",
      "test data/ADP_20_92.csv tensor(2.) tensor(92) 0.017045164480805397\n",
      "test data/ADP_20_96.csv tensor(2.) tensor(96) 0.01698010228574276\n",
      "test data/ADP_20_100.csv tensor(2.) tensor(100) 0.01680625043809414\n",
      "0.016939018853008747 0.00023226103244902108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01672188, 0.01658007, 0.01653229, 0.0165031 , 0.0164219 ,\n",
       "        0.01624622],\n",
       "       [0.01713059, 0.0170101 , 0.01701657, 0.0170566 , 0.01703287,\n",
       "        0.01687261],\n",
       "       [0.01712321, 0.01703407, 0.01705946, 0.01711124, 0.01709593,\n",
       "        0.01694175],\n",
       "       [0.01714675, 0.0170347 , 0.01702821, 0.0170467 , 0.01700473,\n",
       "        0.01683559],\n",
       "       [0.0172102 , 0.01704731, 0.01699369, 0.01697107, 0.01689899,\n",
       "        0.01671441],\n",
       "       [0.01733866, 0.01714106, 0.01707061, 0.01704516, 0.0169801 ,\n",
       "        0.01680625]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p2csvfile(em,es):\n",
    "    filename = 'test data/ADP_'+str(int(em*10))+'_'+str(int(es))+'.csv'\n",
    "    return filename\n",
    "\n",
    "e_m = torch.tensor([1, 1.2, 1.4, 1.6, 1.8, 2])\n",
    "e_s =torch.tensor([80, 84, 88, 92, 96, 100])\n",
    "e_m = torch.tensor([1, 1.2, 1.4, 1.6, 1.8, 2])\n",
    "e_s =torch.tensor([80, 84, 88, 92, 96, 100])\n",
    "relative_l2_error = []\n",
    "for em in e_m:\n",
    "    for es in e_s:\n",
    "        csv_file = p2csvfile(em, es)\n",
    "        test_inner, test_out = csv2data(csv_file, em , es) \n",
    "        l1=((model(test_inner,label='inner')+test_inner[-1]-test_inner[-2])**2).sum()+((model(test_out,label='out')-test_out[-1])**2).sum()\n",
    "        l2 = ((test_inner[-2])**2).sum()+((test_out[-2])**2).sum()\n",
    "        error = torch.sqrt(l1/l2).item()\n",
    "        relative_l2_error.append(error)\n",
    "        print(csv_file,em,es, error)\n",
    "\n",
    "print(np.array(relative_l2_error).mean(), np.array(relative_l2_error).std())\n",
    "np.array(relative_l2_error).reshape(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data/ADP_20_80.csv tensor(2) tensor(80) 0.01733866147696972\n"
     ]
    }
   ],
   "source": [
    "e_m = torch.tensor([2])\n",
    "e_s =torch.tensor([80])\n",
    "relative_l2_error = []\n",
    "for em in e_m:\n",
    "    for es in e_s:\n",
    "        csv_file = p2csvfile(em, es)\n",
    "        test_inner, test_out = csv2data(csv_file, em , es) \n",
    "        l1=((model(test_inner,label='inner')+test_inner[-1]-test_inner[-2])**2).sum()+((model(test_out,label='out')-test_out[-1])**2).sum()\n",
    "        l2 = ((test_inner[-2])**2).sum()+((test_out[-2])**2).sum()\n",
    "        error = torch.sqrt(l1/l2).item()\n",
    "        relative_l2_error.append(error)\n",
    "        print(csv_file,em,es, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
